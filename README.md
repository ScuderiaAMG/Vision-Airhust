# Vision-Airhust
一个在本地部署模型的脚本集
## 对于test脚本：
这些.py文件设计都是为了模型训练。
### test.py
cifar100验证模型，目的是验证移动端RTX 4060 8GB 55W在linux系统是否可以进行训练。
### test2.py
resnet152 / efficientnet_b7训练脚本，不适用于移动端RTX 4060。
### test3.py
resnet152 / efficientnet_b7训练脚本，在优化后理论上适用于移动端RTX 4060，但是实际验证中无法实现。本脚本对于GPU核心、显存、散热、性能释放四方面要求极高，极有可能遇到稳定性问题。
### test4.py
yolov8x的最激进调教训练脚本，仅适用于RTX 4090/RTX 4090D，自动生成覆盖整张图像的边界框标注，标签名与文件夹名称一致，生成PASCAL VOC格式的XML文件，每张原始图像生成100张增强图像，保持正确的边界框标注，包含几何变换、颜色变换、天气效果等，使用最激进的YOLOv8x模型，启用所有增强选项，12小时满负荷训练。但是值得注意的是，这只是半成品代码，实际的结果应该是在环境图片中进行打标，所以对于test4.py来说，前部打标是错误的。
### test5.py
yolov8x最激进调教训练脚本，核心与test4几乎相同，但是修正了环境图片的输入。应当可用。pip install torch torchvision albumentations ultralytics opencv-python tqdm scikit-learn imutils
### test6.py 
测试开学后国赛初赛的实验模型，暂定使用 RTX 4060 M 55W进行训练，暂定采用Resnet152模型。设计显存、核心最大化利用，为保证精度暂时决定进行长时间训练以弥补4060算力不足的问题；正在寻找更优秀的高效算法。   后期发现数据集扩充不足。
### test7.py
修复了test6数据集扩充不足的问题，每个类别可以做到800~1000张图片；已经连续测试训练26小时，可以稳定运行，GPU核心和显存占用稳定在98%以上。  后期发现代码问题epoches不连续训练导致权重无效或低效。（我踏马真是个人物我草）
### test8.py
修复了test7关于epoches不连续训练的问题；增强了数据集扩充能力；修复了一些已知问题。

#### 您需要做的准备：
##### 在background_scene/目录中放置10+张无人机拍摄的场景图片，不需要任何标注，只需原始拍摄图片；
##### 在raw_dataset/目录中准备目标物体图片，按类别分文件夹存放，使用透明背景的PNG格式最佳，如果只有JPG，脚本会自动添加透明背景
##### 示例场景图片要求：固定点位拍摄（同一位置不同时间），包含典型背景变化（光照、天气等），包含目标可能出现区域的空场景，不需要包含实际目标物体
##### 剩下的数据config路径啥的自己看着改吧

## 对于verify脚本
这些verify脚本都是用来进行识别验证的，通过不断扫描数据集内部的照片集进行扫描识别，计算成功率，初步判断可用的模型识别成功率在95%以上，在实际应用中若要追求速度则应该逼近99%~100%。
